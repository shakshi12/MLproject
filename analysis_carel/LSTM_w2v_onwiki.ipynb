{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_w2v_onwiki.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBw9NNWbJ9w3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtkNLbKDYyZ5",
        "outputId": "05581e31-cbad-416a-a1c6-fbd44400867d"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive//My Drive/Andmeteadus/MasinÃµpe/4N/\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5wkqEKXY4EY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c015f543-4cc3-453d-c212-c0d5a8a55fec"
      },
      "source": [
        "data = pd.read_csv(\"cleaned_with_title_am_nam.csv\", sep=\"\\t\")\n",
        "print(data.shape)\n",
        "data.dropna()\n",
        "print(data.shape)\n",
        "w2v = pd.read_csv(\"word2vec_features_with_labels_after_removing_noisy_columns.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1218, 4)\n",
            "(1218, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa0_pZ07ZYfO"
      },
      "source": [
        "#!wget -O w2v.zip https://owncloud.ut.ee/owncloud/index.php/s/3GbKqZi3pHGsDHD/download\n",
        "#!unzip w2v.zip\n",
        "w2vmodel = gensim.models.KeyedVectors.load_word2vec_format(\"model.bin\", binary=True, unicode_errors='replace')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g9AN1MApq_d"
      },
      "source": [
        "train, test = train_test_split(data, train_size=0.8, test_size=0.2, shuffle=True)\n",
        "def preprocess(data):\n",
        "  new_articles = []\n",
        "  for i in data.iterrows():\n",
        "    if type(i[1][\"title\"]) == float or type(i[1][\"article\"]) == float:\n",
        "      new_articles.append(\"\")\n",
        "      continue\n",
        "\n",
        "    new_articles.append(i[1][\"title\"]+\" \"+i[1][\"article\"])\n",
        "  data[\"data\"] = np.array(new_articles)\n",
        "  return data\n",
        "#data.head()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YesLP-TotUT3",
        "outputId": "e235220e-1193-41c9-d806-27603e843b46"
      },
      "source": [
        "le = LabelEncoder()\n",
        "train = preprocess(train)\n",
        "train_X = train[\"data\"]\n",
        "train_y = train[\"label\"]\n",
        "train_y = to_categorical(le.fit_transform(train_y))\n",
        "\n",
        "test = preprocess(test)\n",
        "test_X = test[\"data\"]\n",
        "test_y = test[\"label\"]\n",
        "test_y = to_categorical(le.transform(test_y))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkdP9hYVt8sH",
        "outputId": "94d32366-1f24-4e26-f0fe-38fa90818756"
      },
      "source": [
        "test_y.shape, test_X.shape, train_X.shape, train_y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((244, 2), (244,), (974,), (974, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpWuB-prpoV6",
        "outputId": "49af961b-e5cf-4224-f8ea-4939247713fa"
      },
      "source": [
        "vocabulary_size = 10000\n",
        "tokenizer = Tokenizer(num_words=vocabulary_size,oov_token=\"XXX\") \n",
        "tokenizer.fit_on_texts(train_X)\n",
        "X_train_vec = tokenizer.texts_to_sequences(train_X)\n",
        "X_test_vec = tokenizer.texts_to_sequences(test_X)\n",
        "pikkus = 1000\n",
        "X_train_pad = sequence.pad_sequences(X_train_vec, maxlen=pikkus)\n",
        "X_test_pad = sequence.pad_sequences(X_test_vec, maxlen=pikkus)\n",
        "y_train_vec = train_y\n",
        "y_test_vec = test_y\n",
        "checked_vocabulary_size = min(vocabulary_size, len(tokenizer.word_index)+1)\n",
        "embedding_size = 300\n",
        "embedding_matrix = np.zeros((checked_vocabulary_size, embedding_size))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i>=vocabulary_size:\n",
        "    continue\n",
        "  try:\n",
        "    embedding_matrix[i] = w2vmodel[word]\n",
        "  except KeyError:\n",
        "    embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),embedding_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(checked_vocabulary_size,embedding_size,weights=[embedding_matrix],trainable=True))\n",
        "model.add(LSTM(35, return_sequences=True, recurrent_dropout=0.2, dropout=0.1))\n",
        "model.add(LSTM(35, return_sequences=False, recurrent_dropout=0.2, dropout=0.1))\n",
        "model.add(Dense(10, activation=\"relu\"))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 300)         3000000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 35)          47040     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 35)                9940      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                360       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 3,057,362\n",
            "Trainable params: 3,057,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puWDyWJLtQI-",
        "outputId": "7f79d011-1ebe-464a-f2ec-b19d8b670676"
      },
      "source": [
        "model.fit(X_train_pad, y_train_vec,\n",
        "          batch_size=64,\n",
        "          epochs=4,\n",
        "          validation_data=(X_test_pad, y_test_vec))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "16/16 [==============================] - 62s 4s/step - loss: 0.6786 - accuracy: 0.5657 - val_loss: 0.6514 - val_accuracy: 0.5861\n",
            "Epoch 2/4\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.5831 - accuracy: 0.7033 - val_loss: 0.5900 - val_accuracy: 0.7008\n",
            "Epoch 3/4\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.4291 - accuracy: 0.8326 - val_loss: 0.5507 - val_accuracy: 0.7295\n",
            "Epoch 4/4\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.2525 - accuracy: 0.9097 - val_loss: 0.6439 - val_accuracy: 0.7336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f584f8d61d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ZWrsV_OD4v",
        "outputId": "e59c7bfe-b6f2-4c38-903e-a7dbfa9a1005"
      },
      "source": [
        "y_pred_vec = model.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred_vec, axis=1)\n",
        "y_true = np.argmax(y_test_vec, axis=1)\n",
        "\n",
        "f1_score(y_true, y_pred), accuracy_score(y_true, y_pred)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6666666666666666, 0.7336065573770492)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}