{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_w2v_onour.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBZG9gDNv35N"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Bidirectional, Input,GlobalMaxPool1D, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkuXkuC8wdPT",
        "outputId": "569f3d9e-943b-4af6-d177-372ceae77e18"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"/content/drive//My Drive/Andmeteadus/MasinÃµpe/4N/\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LEw8yonwI2I"
      },
      "source": [
        "wordvec_loc = \"word2vec_features_with_labels_after_removing_noisy_columns.csv\"\n",
        "w2v = pd.read_csv(wordvec_loc)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3OE3lOkwZPu"
      },
      "source": [
        "data_path = \"cleaned_am_nam_articles.csv\"\n",
        "data = pd.read_csv(data_path)\n",
        "data = data.dropna()\n",
        "train, test = train_test_split(data, train_size=0.8, test_size=0.2, shuffle=True)\n",
        "train_articles = train[\"article\"]\n",
        "train_labels = train[\"label\"]\n",
        "test_articles = test[\"article\"]\n",
        "test_labels = test[\"label\"]\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(test_labels)\n",
        "y_train = le.transform(train_labels)\n",
        "y_test = le.transform(test_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZsRFzDLKcxi",
        "outputId": "2a5b1cad-c3d2-4b93-d003-4dfab24072f2"
      },
      "source": [
        "print(\"FOR TRAIN\")\n",
        "for i, el in enumerate(train_articles):\n",
        "  if type(el) != str:\n",
        "    print(i, el)\n",
        "print(\"FOR TEST\")\n",
        "for i, el in enumerate(test_articles):\n",
        "  if (type(el)) != str:\n",
        "    print(i, el)\n",
        "  if el == np.nan:\n",
        "    print(i, el)\n",
        "\n",
        "print(w2v.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR TRAIN\n",
            "FOR TEST\n",
            "(1087, 2840)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHFRlxZ4FitG",
        "outputId": "13053a7b-ec14-4850-a0d0-2901f16fef6c"
      },
      "source": [
        "vocabulary_size = 500\n",
        "tokenizer = Tokenizer(num_words=vocabulary_size,oov_token=\"XXX\") \n",
        "tokenizer.fit_on_texts(train_articles)\n",
        "X_train_vec = tokenizer.texts_to_sequences(train_articles)\n",
        "X_test_vec = tokenizer.texts_to_sequences(test_articles)\n",
        "pikkus = 1000\n",
        "X_train_pad = sequence.pad_sequences(X_train_vec, maxlen=pikkus)\n",
        "X_test_pad = sequence.pad_sequences(X_test_vec, maxlen=pikkus)\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "checked_vocabulary_size = min(vocabulary_size, len(tokenizer.word_index)+1)\n",
        "embedding_size = w2v.shape[0]\n",
        "embedding_matrix = np.zeros((checked_vocabulary_size, embedding_size))\n",
        "count = 0\n",
        "count2 = 0\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i>=vocabulary_size:\n",
        "    continue\n",
        "  try:\n",
        "    count2 += 1\n",
        "    embedding_matrix[i] = w2v[word]\n",
        "  except KeyError:\n",
        "    count += 1\n",
        "    embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),embedding_size)\n",
        "\n",
        "print(count, count2)\n",
        "model = Sequential()\n",
        "model.add(Embedding(checked_vocabulary_size,embedding_size,weights=[embedding_matrix],trainable=True))\n",
        "model.add(LSTM(35, return_sequences=True, recurrent_dropout=0.2, dropout=0.1))\n",
        "model.add(LSTM(35, return_sequences=False, recurrent_dropout=0.2, dropout=0.1))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "323 499\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 1087)        543500    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, None, 35)          157220    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 35)                9940      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 72        \n",
            "=================================================================\n",
            "Total params: 710,732\n",
            "Trainable params: 710,732\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iDxQi-0SBj2",
        "outputId": "85a98ff1-5928-4d71-ce72-cd0536c243ff"
      },
      "source": [
        "print(X_test_pad.shape, y_test_cat.shape, X_train_pad.shape, y_train_cat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(217, 1000) (217, 2) (867, 1000) (867, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws9KcisDR8fd",
        "outputId": "5fa3963d-5361-4fd1-e788-6f7d6e16e88b"
      },
      "source": [
        "model.fit(X_train_pad, y_train_cat,\n",
        "          batch_size=64,\n",
        "          epochs=5,\n",
        "          validation_data=(X_test_pad, y_test_cat))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "14/14 [==============================] - 118s 8s/step - loss: 0.6863 - accuracy: 0.5536 - val_loss: 0.6670 - val_accuracy: 0.6359\n",
            "Epoch 2/5\n",
            "14/14 [==============================] - 117s 8s/step - loss: 0.6513 - accuracy: 0.6240 - val_loss: 0.6407 - val_accuracy: 0.6406\n",
            "Epoch 3/5\n",
            "14/14 [==============================] - 118s 8s/step - loss: 0.5877 - accuracy: 0.7093 - val_loss: 0.5933 - val_accuracy: 0.6912\n",
            "Epoch 4/5\n",
            "14/14 [==============================] - 117s 8s/step - loss: 0.5011 - accuracy: 0.7670 - val_loss: 0.5711 - val_accuracy: 0.6912\n",
            "Epoch 5/5\n",
            "14/14 [==============================] - 116s 8s/step - loss: 0.4154 - accuracy: 0.8281 - val_loss: 0.5445 - val_accuracy: 0.7097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d421936d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNKw_r3oJOGd",
        "outputId": "dcd1ef30-d031-46e1-e5ff-2a7dbed5e4ae"
      },
      "source": [
        "y_pred_cat = model.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred_cat, axis=1)\n",
        "y_true = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "f1_score(y_true, y_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6519337016574586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcGjF7n8KSd1"
      },
      "source": [
        "\n",
        "def tootle_4(tekst):\n",
        "  global tokenizer, pikkus, sequence\n",
        "  toodeldudTekst = sequence.pad_sequences(tokenizer.texts_to_sequences([tekst]), maxlen=pikkus)\n",
        "  return toodeldudTekst \n",
        "def ennusta_4(toodeldudTekst):\n",
        "  global mudel4\n",
        "  res = np.argmax(mudel4.predict(toodeldudTekst), axis=1)\n",
        "  return res\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}