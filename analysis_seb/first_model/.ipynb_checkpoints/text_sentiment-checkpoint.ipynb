{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import text_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torch.utils.data.dataset import random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data paths : creating the files for training and testing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastien/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('./.data'):\n",
    "    os.mkdir('./.data')\n",
    "#train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root='./.data', ngrams=NGRAMS, vocab=None)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take as input a file with title, article and label, and we convert it into another file that respects the need of preprocessing (csv, delimiter=\",\", columns article and label necessary)\n",
    "\n",
    "initial_data_path=\"./data/initial_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path, testing=False):\n",
    "    data=pd.read_csv(initial_data_path, delimiter=\",\")\n",
    "    nb=data.shape[0]\n",
    "    ghost_col=[0]*nb\n",
    "    articles=data['article']\n",
    "    labels=list(data['label'])\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i]==\"am\":\n",
    "            labels[i]=1\n",
    "        elif labels[i]==\"nam\":\n",
    "            labels[i]=0\n",
    "        else:\n",
    "            labels[i]=0\n",
    "\n",
    "    data2=pd.DataFrame(columns=[])\n",
    "    data2.insert(0, \"article\", articles, True)\n",
    "    data2.insert(1, \"label\", labels, True)\n",
    "    print(data2.head())\n",
    "    print(data2.tail())\n",
    "\n",
    "    #and the  we store it the new file\n",
    "    data2 = data2.rename(columns = {'Unnamed: 0':'index'})\n",
    "    \n",
    "    data2.to_csv(\"./data/data_intermediary.csv\", sep=\",\", index_label=\"index\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we split the data\n",
    "def split_data_for_train_test():\n",
    "    data=pd.read_csv(\"./data/data_intermediary.csv\", sep=\",\", index_col=\"index\")\n",
    "    data=data.sample(frac = 1)\n",
    "    nb_elems=data.shape[0]\n",
    "    train_data=data.iloc[:int(nb_elems*0.8)]\n",
    "    test_data=data.iloc[int(nb_elems*0.8):]\n",
    "    print(train_data.shape)\n",
    "    print(test_data.shape)\n",
    "    print(train_data.columns)\n",
    "    print(train_data.head)\n",
    "    print(test_data.head)\n",
    "    train_data.to_csv(\"./data/train_2.csv\", sep=\",\", index_label=\"index\")\n",
    "    test_data.to_csv(\"./data/test_2.csv\", sep=\",\", index_label=\"index\")\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             article  label\n",
      "0  Bernie Madoff, who is scheduled to be sentence...      1\n",
      "1  Published\\n\\nOne of the world's leading fund m...      1\n",
      "2       'webPage': {'inLanguages': [{'code': 'en'}]}      1\n",
      "3  WASHINGTON (AP) â An American security contr...      1\n",
      "4  A senior figure in the Bitcoin Foundation, whi...      1\n",
      "                                                article  label\n",
      "1082  The signing of the deal normalising relations ...      0\n",
      "1083  Slipping a $20 bill to the woman at the DMV mi...      0\n",
      "1084  As fraudsters continually refine their techniq...      0\n",
      "1085  Dr. Arif Alvi was born in 1949 and completed h...      0\n",
      "1086  KUALA LUMPUR, Nov 2  Life was fine for vetera...      0\n",
      "(869, 2)\n",
      "(218, 2)\n",
      "Index(['article', 'label'], dtype='object')\n",
      "<bound method NDFrame.head of                                                  article  label\n",
      "index                                                          \n",
      "39          'webPage': {'inLanguages': [{'code': 'en'}]}      1\n",
      "855    Lucy DâOrsi, national policing lead for prot...      0\n",
      "385    SAO PAULO/BRASILIA: Brazil's central bank effe...      0\n",
      "389    TG-345\\n\\nWASHINGTON  The U.S. Department of ...      1\n",
      "514    New York (CNN Business) Texas tech mogul Rober...      1\n",
      "...                                                  ...    ...\n",
      "93     Cachiros\\nFounded 1990s\\nYears active 1990s-pr...      1\n",
      "413    PANAMA CITY.- The Financial Pacific case has b...      1\n",
      "1062   The global impact of money laundering is stagg...      0\n",
      "976    MOSCOW, February 7. /TASS/. Rescuers of the se...      0\n",
      "22     Video\\n\\nActress Lori Loughlin and her fashion...      1\n",
      "\n",
      "[869 rows x 2 columns]>\n",
      "<bound method NDFrame.head of                                                  article  label\n",
      "index                                                          \n",
      "650    The fintech Modulr has today launched Confirma...      0\n",
      "949    image copyrightAP\\n\\nGerman police are investi...      0\n",
      "697    Most Asia-Pacific (APAC) financial institution...      0\n",
      "541    (Yicai Global) June 3 -- GSX Techedu alleges t...      1\n",
      "998    WNK4 inhibition of ENaC is independent of Nedd...      0\n",
      "...                                                  ...    ...\n",
      "366    Treasury Secretary Steven Mnuchin is in troubl...      1\n",
      "543    image copyrightReuters\\n\\nA former Mexican sec...      1\n",
      "542    [et_pb_section bb_built=1? fullwidth=on spe...      1\n",
      "868    European interior ministers have pushed the fi...      0\n",
      "1011   Gaston Browne is the 4th and current Prime Min...      0\n",
      "\n",
      "[218 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "preprocess_data(initial_data_path)\n",
    "split_data_for_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path=\"./data/train_2.csv\"\n",
    "test_csv_path=\"./data/test_2.csv\" #this contains the testing data: only columns \"article\" and \"label\" (and possibly others)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import io\n",
    "from torchtext.utils import download_from_url, extract_archive, unicode_csv_reader\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.vocab import Vocab\n",
    "from tqdm import tqdm\n",
    "from  torchtext.datasets.text_classification import _csv_iterator, _create_data_from_iterator, TextClassificationDataset\n",
    "\n",
    "\n",
    "NGRAMS=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _csv_iterator(data_path, ngrams, yield_cls=False, label=-1):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    data=pd.read_csv(data_path, delimiter=\",\")\n",
    "    for index, row in data.iterrows():\n",
    "        \n",
    "        tokens = ' '.join([str(row[\"article\"])])\n",
    "        #print(row[5])\n",
    "        tokens=tokenizer(tokens)\n",
    "        if yield_cls:\n",
    "            yield row[0], row[\"label\"], ngrams_iterator(tokens, ngrams)\n",
    "        else:\n",
    "            yield ngrams_iterator(tokens, ngrams)\n",
    "\n",
    "\n",
    "def _create_data_from_iterator(vocab, iterator, include_unk):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with tqdm(unit_scale=0, unit='lines') as t:\n",
    "        for index, cls, tokens in iterator:\n",
    "            if include_unk:\n",
    "                tokens = torch.tensor([vocab[token] for token in tokens])\n",
    "            else:\n",
    "                token_ids = list(filter(lambda x: x is not Vocab.UNK, [vocab[token] for token in tokens]))\n",
    "                tokens = torch.tensor(token_ids)\n",
    "            if len(tokens) == 0:\n",
    "                logging.info('Row contains no tokens.')\n",
    "            data.append((index, cls, tokens))\n",
    "            labels.append(cls)\n",
    "            t.update(1)\n",
    "    return data, set(labels)\n",
    "\n",
    "\n",
    "\n",
    "def create_iterator_from_file_for_testing(vocab, ngrams, data, include_unk=False):\n",
    "    #each element contains text and label\n",
    "    article_index=1\n",
    "    label_index=2\n",
    "    datas = []\n",
    "    labels = []\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    \n",
    "    with tqdm(unit_scale=0, unit='lines') as t:\n",
    "        for index, row in data.iterrows():\n",
    "            \n",
    "            tokens = ' '.join([str(row['article'])])\n",
    "            tokens=tokenizer(tokens)\n",
    "            cls=int(row['label'])\n",
    "            \n",
    "            index=row.name\n",
    "            \n",
    "            if include_unk:\n",
    "                tokens = torch.tensor([vocab[token] for token in tokens])\n",
    "            else:\n",
    "                token_ids = list(filter(lambda x: x is not Vocab.UNK, [vocab[token] for token in tokens]))\n",
    "                tokens = torch.tensor(token_ids)\n",
    "            if len(tokens) == 0:\n",
    "                logging.info('Row contains no tokens.')\n",
    "            \n",
    "            datas.append((index, cls, tokens))\n",
    "            labels.append(cls)\n",
    "            t.update(1)\n",
    "    return datas, set(labels)\n",
    "\n",
    "\n",
    "#1: am\n",
    "#0: nam\n",
    "def setup_datasets(train_csv_path, test_csv_path, include_unk=False):\n",
    "    iterator=_csv_iterator(train_csv_path, NGRAMS)\n",
    "    vocab = build_vocab_from_iterator(iterator)\n",
    "    train_data, train_labels = _create_data_from_iterator(vocab, _csv_iterator(train_csv_path, NGRAMS, yield_cls=True, label=0), include_unk)\n",
    "    test_data, test_labels = _create_data_from_iterator(vocab, _csv_iterator(test_csv_path, NGRAMS, yield_cls=True, label=0), include_unk)\n",
    "\n",
    "\n",
    "    return TextClassificationDataset(vocab, train_data, train_labels), TextClassificationDataset(vocab, test_data, test_labels), vocab\n",
    "\n",
    "#this is the version where we don't have the tarining data\n",
    "def setup_datasets_testing(vocab, test_csv_path, include_unk=False):\n",
    "    data=pd.read_csv(test_csv_path, delimiter=\",\")\n",
    "    test_data, test_labels=create_iterator_from_file_for_testing(vocab, NGRAMS, data)\n",
    "    #test_data, test_labels = _create_data_from_iterator(vocab, _csv_iterator(test_csv_path, NGRAMS, yield_cls=True, label=0), include_unk)\n",
    "\n",
    "\n",
    "    return TextClassificationDataset(vocab, test_data, test_labels), vocab\n",
    "\n",
    "\n",
    "def setup_datasets_testing_from_df(vocab, df, include_unk=False):\n",
    "    test_data, test_labels=create_iterator_from_file_for_testing(vocab, NGRAMS, df)\n",
    "    #test_data, test_labels = _create_data_from_iterator(vocab, _csv_iterator(test_csv_path, NGRAMS, yield_cls=True, label=0), include_unk)\n",
    "\n",
    "\n",
    "    return TextClassificationDataset(vocab, test_data, test_labels), vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "869lines [00:01, 718.91lines/s]\n",
      "869lines [00:02, 352.40lines/s]\n",
      "218lines [00:00, 401.88lines/s]\n",
      "218lines [00:00, 581.03lines/s]\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.pkl', 'rb') as f1:\n",
    "    vocab = pickle.load(f1)\n",
    "    \n",
    "\n",
    "train_dataset, test_dataset, vocab=setup_datasets(train_csv_path, test_csv_path) #we will not use test_dataset from this function\n",
    "test_dataset, vocab=setup_datasets_testing(vocab, test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n",
    "    \n",
    "    def predict(self, df, vocab):\n",
    "        test_dataset, vocab=setup_datasets_testing_from_df(vocab, df)\n",
    "        all_indexes=[]\n",
    "        predictions=[]\n",
    "        data = DataLoader(test_dataset, batch_size=df.shape[0], shuffle=False, collate_fn=generate_batch)\n",
    "        for indexes, text, offsets, cls in data:\n",
    "            text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "            with torch.no_grad():\n",
    "                #print(indexes, cls)\n",
    "                #print(text, offsets)\n",
    "                output = self.forward(text, offsets)\n",
    "                all_indexes=indexes\n",
    "                predictions=output\n",
    "                \n",
    "        return all_indexes, predictions\n",
    "\n",
    "\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    #print(type(batch), len(batch[0]), batch[0][1], batch[1][1])\n",
    "    #print([entry[0] for entry in batch])\n",
    "    indexes=torch.tensor([int(entry[0]) for entry in batch])\n",
    "    label = torch.tensor([int(entry[1]) for entry in batch])\n",
    "    text = [entry[2] for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    # torch.Tensor.cumsum returns the cumulative sum\n",
    "    # of elements in the dimension dim.\n",
    "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    text=text.type(torch.LongTensor)\n",
    "    return indexes, text, offsets, label\n",
    "\n",
    "\n",
    "def train_func(sub_train_):\n",
    "    \n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "    for i, (indexes, text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    \n",
    "    data = DataLoader(data_, batch_size=1, shuffle=False, collate_fn=generate_batch)\n",
    "    for indexes, text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            #print(indexes, cls)\n",
    "            #print(text, offsets)\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=[]\n",
    "test_score=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0117(train)\t|\tAcc: 93.8%(train)\n",
      "\tLoss: 0.0003(valid)\t|\tAcc: 77.3%(valid)\n",
      "Epoch: 2  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0114(train)\t|\tAcc: 93.5%(train)\n",
      "\tLoss: 0.0000(valid)\t|\tAcc: 59.1%(valid)\n",
      "Epoch: 3  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0088(train)\t|\tAcc: 95.9%(train)\n",
      "\tLoss: 0.0025(valid)\t|\tAcc: 93.2%(valid)\n",
      "Epoch: 4  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0069(train)\t|\tAcc: 97.8%(train)\n",
      "\tLoss: 0.0120(valid)\t|\tAcc: 81.8%(valid)\n",
      "Epoch: 5  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0065(train)\t|\tAcc: 97.6%(train)\n",
      "\tLoss: 0.0011(valid)\t|\tAcc: 90.9%(valid)\n",
      "Epoch: 6  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0060(train)\t|\tAcc: 97.8%(train)\n",
      "\tLoss: 0.0013(valid)\t|\tAcc: 93.2%(valid)\n",
      "Epoch: 7  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0052(train)\t|\tAcc: 98.4%(train)\n",
      "\tLoss: 0.0013(valid)\t|\tAcc: 93.2%(valid)\n",
      "Epoch: 8  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0048(train)\t|\tAcc: 99.5%(train)\n",
      "\tLoss: 0.0026(valid)\t|\tAcc: 97.7%(valid)\n",
      "Epoch: 9  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0047(train)\t|\tAcc: 99.3%(train)\n",
      "\tLoss: 0.0012(valid)\t|\tAcc: 93.2%(valid)\n",
      "Epoch: 10  | time in 0 minutes, 2 seconds\n",
      "\tLoss: 0.0046(train)\t|\tAcc: 99.0%(train)\n",
      "\tLoss: 0.0011(valid)\t|\tAcc: 93.2%(valid)\n"
     ]
    }
   ],
   "source": [
    "#Only for training\n",
    "\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    train_score.append(train_acc)\n",
    "    test_score.append(valid_acc)\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matpotlib.pyplot as plt\n",
    "\n",
    "\n",
    "Y=[54.5, 54.5, 65.9, 59.1, 70.5, 72.7, 75, ]\n",
    "plt.plot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset...\n",
      "\tLoss: 0.0000(test)\t|\tAcc: 87.2%(test)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(test_dataset)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "218lines [00:00, 580.81lines/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "         210, 211, 212, 213, 214, 215, 216, 217]),\n",
       " tensor([[-6.0483e+00,  6.1615e+00],\n",
       "         [ 3.2518e+00, -3.1936e+00],\n",
       "         [-4.5050e+00,  4.5158e+00],\n",
       "         [-1.1660e+00,  1.2309e+00],\n",
       "         [-8.4100e-01,  9.4153e-01],\n",
       "         [ 4.8521e+00, -4.7439e+00],\n",
       "         [ 1.1957e+00, -1.1448e+00],\n",
       "         [-5.4291e+00,  5.4761e+00],\n",
       "         [ 3.2548e+00, -3.2811e+00],\n",
       "         [ 1.8013e+00, -1.7149e+00],\n",
       "         [-1.1942e+00,  1.3200e+00],\n",
       "         [-5.6169e+00,  5.5803e+00],\n",
       "         [-5.9725e-01,  6.2647e-01],\n",
       "         [-2.0302e+00,  2.0029e+00],\n",
       "         [-2.9326e+00,  2.9560e+00],\n",
       "         [ 2.5561e+00, -2.5247e+00],\n",
       "         [ 2.4658e+00, -2.4391e+00],\n",
       "         [-8.7405e-02,  1.0798e-01],\n",
       "         [-4.9287e+00,  4.9609e+00],\n",
       "         [-3.4395e+00,  3.4143e+00],\n",
       "         [-8.7465e-01,  7.8676e-01],\n",
       "         [ 1.2760e+00, -1.1901e+00],\n",
       "         [ 1.0144e+00, -1.0341e+00],\n",
       "         [-2.4778e+00,  2.5318e+00],\n",
       "         [ 4.6753e+00, -4.7387e+00],\n",
       "         [ 2.8596e+00, -2.8526e+00],\n",
       "         [ 1.9426e+00, -1.8155e+00],\n",
       "         [ 1.8331e+00, -1.7631e+00],\n",
       "         [ 2.3438e+00, -2.2227e+00],\n",
       "         [ 4.8201e+00, -4.8204e+00],\n",
       "         [ 6.9341e+00, -6.9009e+00],\n",
       "         [-2.0802e+00,  2.0527e+00],\n",
       "         [-4.2938e+00,  4.3132e+00],\n",
       "         [-2.6220e+00,  2.7163e+00],\n",
       "         [ 2.3483e+00, -2.2344e+00],\n",
       "         [ 1.1717e+00, -1.0845e+00],\n",
       "         [-2.0464e+00,  2.0168e+00],\n",
       "         [ 6.5402e-01, -6.1499e-01],\n",
       "         [ 1.6326e+00, -1.5975e+00],\n",
       "         [ 1.9161e+00, -1.6826e+00],\n",
       "         [ 6.1012e-01, -6.3203e-01],\n",
       "         [ 4.2866e+00, -4.3024e+00],\n",
       "         [ 3.6364e+00, -3.6010e+00],\n",
       "         [-5.1680e+00,  5.1306e+00],\n",
       "         [ 4.6236e+00, -4.5591e+00],\n",
       "         [ 3.0389e+00, -3.1498e+00],\n",
       "         [ 2.2915e-01, -1.6484e-01],\n",
       "         [-7.0866e-01,  7.7204e-01],\n",
       "         [ 2.0638e+00, -1.9193e+00],\n",
       "         [-6.0643e+00,  6.1657e+00],\n",
       "         [ 1.7653e+00, -1.7156e+00],\n",
       "         [ 3.4319e+00, -3.3508e+00],\n",
       "         [ 2.5900e+00, -2.5423e+00],\n",
       "         [-2.6774e+00,  2.7480e+00],\n",
       "         [-2.9020e+00,  2.9023e+00],\n",
       "         [ 2.4099e+00, -2.3732e+00],\n",
       "         [-1.6576e+00,  1.7577e+00],\n",
       "         [ 4.4791e+00, -4.3747e+00],\n",
       "         [-3.7147e+00,  3.6573e+00],\n",
       "         [-5.2516e+00,  5.1417e+00],\n",
       "         [ 1.3167e+00, -1.1868e+00],\n",
       "         [-1.0254e+00,  1.1096e+00],\n",
       "         [-6.5080e+00,  6.5938e+00],\n",
       "         [ 3.1765e+00, -3.1201e+00],\n",
       "         [-3.7694e+00,  3.7967e+00],\n",
       "         [ 1.8107e+00, -1.7642e+00],\n",
       "         [-8.3145e-01,  8.7837e-01],\n",
       "         [-2.1709e+00,  2.2150e+00],\n",
       "         [-4.7628e-01,  5.1774e-01],\n",
       "         [-3.4676e+00,  3.4941e+00],\n",
       "         [-4.7102e-01,  5.6821e-01],\n",
       "         [ 5.4012e+00, -5.3267e+00],\n",
       "         [-2.4523e+00,  2.4103e+00],\n",
       "         [ 1.8803e+00, -1.8372e+00],\n",
       "         [ 4.5360e+00, -4.4160e+00],\n",
       "         [ 1.1049e+00, -1.0282e+00],\n",
       "         [ 3.2327e+00, -3.3175e+00],\n",
       "         [-1.8694e-01,  2.1994e-01],\n",
       "         [ 2.7660e-01, -2.0545e-01],\n",
       "         [ 2.7916e+00, -2.6932e+00],\n",
       "         [ 5.9916e-02,  3.8363e-02],\n",
       "         [ 1.2454e+00, -1.2060e+00],\n",
       "         [ 4.1310e+00, -4.1401e+00],\n",
       "         [-3.7178e-01,  4.5322e-01],\n",
       "         [-2.5733e+00,  2.5486e+00],\n",
       "         [-2.8331e+00,  2.8401e+00],\n",
       "         [ 1.2979e+00, -1.3011e+00],\n",
       "         [ 8.5683e-01, -7.7776e-01],\n",
       "         [ 2.2869e+00, -2.2220e+00],\n",
       "         [-2.4966e+00,  2.5161e+00],\n",
       "         [ 4.7242e+00, -4.7041e+00],\n",
       "         [-5.0359e-01,  5.8642e-01],\n",
       "         [-2.4507e+00,  2.5660e+00],\n",
       "         [-2.5041e+00,  2.4481e+00],\n",
       "         [-3.8273e+00,  3.8240e+00],\n",
       "         [-3.8562e+00,  4.0246e+00],\n",
       "         [-2.1958e+00,  2.1582e+00],\n",
       "         [-2.3159e+00,  2.3686e+00],\n",
       "         [-6.3077e-02,  2.1969e-01],\n",
       "         [ 4.0137e+00, -3.8989e+00],\n",
       "         [ 4.2932e+00, -4.1656e+00],\n",
       "         [ 4.4255e+00, -4.4123e+00],\n",
       "         [ 1.6993e+00, -1.6395e+00],\n",
       "         [ 1.0926e+00, -1.0396e+00],\n",
       "         [-1.5525e+00,  1.5867e+00],\n",
       "         [ 5.3067e-01, -4.4849e-01],\n",
       "         [ 3.0747e+00, -3.0485e+00],\n",
       "         [ 4.2181e+00, -4.0841e+00],\n",
       "         [ 2.6790e+00, -2.3775e+00],\n",
       "         [-2.0478e+00,  2.0257e+00],\n",
       "         [-3.9122e+00,  3.8589e+00],\n",
       "         [-4.7354e-02,  6.0890e-03],\n",
       "         [ 6.3066e+00, -6.2838e+00],\n",
       "         [ 3.7580e+00, -3.7580e+00],\n",
       "         [-3.0770e+00,  3.1441e+00],\n",
       "         [ 2.1658e+00, -2.0867e+00],\n",
       "         [-1.7219e+00,  1.6854e+00],\n",
       "         [-2.8286e+00,  2.8641e+00],\n",
       "         [ 1.8532e+00, -1.7983e+00],\n",
       "         [ 1.5367e+00, -1.4161e+00],\n",
       "         [-8.2840e+00,  8.2015e+00],\n",
       "         [-7.1391e-01,  7.3472e-01],\n",
       "         [-3.5366e+00,  3.5129e+00],\n",
       "         [-1.5295e+00,  1.4978e+00],\n",
       "         [-6.0120e+00,  6.0467e+00],\n",
       "         [ 1.6727e+00, -1.7085e+00],\n",
       "         [ 1.6800e+00, -1.6396e+00],\n",
       "         [ 4.2535e+00, -4.2505e+00],\n",
       "         [ 3.2331e+00, -3.2210e+00],\n",
       "         [-2.5064e+00,  2.4669e+00],\n",
       "         [ 5.4630e+00, -5.3315e+00],\n",
       "         [-1.4485e+00,  1.4674e+00],\n",
       "         [-7.5926e-01,  6.9509e-01],\n",
       "         [ 3.5692e+00, -3.3675e+00],\n",
       "         [-2.0669e+00,  2.1686e+00],\n",
       "         [-1.0539e+00,  1.0395e+00],\n",
       "         [-8.3131e-01,  8.9250e-01],\n",
       "         [-3.2661e+00,  3.3477e+00],\n",
       "         [ 3.1256e+00, -3.1822e+00],\n",
       "         [-2.6703e+00,  2.6194e+00],\n",
       "         [ 3.7046e+00, -3.6786e+00],\n",
       "         [-8.7164e-01,  9.0880e-01],\n",
       "         [-5.1643e-02,  2.9155e-01],\n",
       "         [ 4.1257e+00, -4.0319e+00],\n",
       "         [-2.6948e+00,  2.8031e+00],\n",
       "         [ 1.9181e+00, -1.8644e+00],\n",
       "         [-1.8183e+00,  1.8636e+00],\n",
       "         [-1.2700e+00,  1.4537e+00],\n",
       "         [-4.9593e+00,  4.9270e+00],\n",
       "         [-1.2835e-01,  2.1674e-01],\n",
       "         [-6.1450e-01,  6.8463e-01],\n",
       "         [-3.3852e+00,  3.3457e+00],\n",
       "         [-1.1342e+00,  1.1948e+00],\n",
       "         [ 1.6547e+01, -1.6442e+01],\n",
       "         [-1.7789e+00,  1.7612e+00],\n",
       "         [ 1.3444e+00, -1.3708e+00],\n",
       "         [-2.0819e+00,  2.0977e+00],\n",
       "         [-1.3001e+00,  1.3509e+00],\n",
       "         [-3.2606e+00,  3.3010e+00],\n",
       "         [-1.7909e+00,  1.8512e+00],\n",
       "         [ 1.7065e-01, -1.1907e-01],\n",
       "         [-3.3543e+00,  3.3793e+00],\n",
       "         [-3.5236e+00,  3.5484e+00],\n",
       "         [ 7.6207e-01, -6.3152e-01],\n",
       "         [-1.9576e+00,  1.9695e+00],\n",
       "         [-1.7627e+00,  1.7076e+00],\n",
       "         [-1.1684e+00,  1.2513e+00],\n",
       "         [-5.2397e+00,  5.2766e+00],\n",
       "         [ 2.0125e+00, -1.9352e+00],\n",
       "         [ 3.9827e+00, -3.9674e+00],\n",
       "         [ 2.4567e+00, -2.3506e+00],\n",
       "         [ 2.3698e+00, -2.4992e+00],\n",
       "         [ 5.3304e+00, -5.2589e+00],\n",
       "         [-9.5213e-01,  1.0488e+00],\n",
       "         [ 3.4174e-01, -2.3995e-01],\n",
       "         [-5.0081e-01,  5.2632e-01],\n",
       "         [ 3.3340e-01, -2.2873e-01],\n",
       "         [-3.3037e+00,  3.3421e+00],\n",
       "         [-3.6593e-01,  5.0310e-01],\n",
       "         [ 1.8279e+00, -1.8614e+00],\n",
       "         [-3.3267e+00,  3.3981e+00],\n",
       "         [-3.6157e-01,  4.5362e-01],\n",
       "         [ 2.2057e+00, -2.0983e+00],\n",
       "         [ 4.0259e+00, -3.9876e+00],\n",
       "         [-1.1240e+00,  1.1742e+00],\n",
       "         [-2.2409e+00,  2.2466e+00],\n",
       "         [ 1.9775e+00, -2.0020e+00],\n",
       "         [-6.4587e-01,  6.3726e-01],\n",
       "         [-1.5703e+00,  1.6656e+00],\n",
       "         [-3.5029e+00,  3.5530e+00],\n",
       "         [-4.9518e+00,  4.9977e+00],\n",
       "         [ 1.6774e+00, -1.6327e+00],\n",
       "         [-4.5165e+00,  4.5061e+00],\n",
       "         [-1.1221e+00,  1.2258e+00],\n",
       "         [-2.6960e+00,  2.7667e+00],\n",
       "         [-1.8411e-01,  2.2591e-01],\n",
       "         [ 2.7260e+00, -2.5943e+00],\n",
       "         [ 4.1935e+00, -4.1560e+00],\n",
       "         [ 3.4792e+00, -3.4127e+00],\n",
       "         [ 2.0724e+00, -2.0450e+00],\n",
       "         [-4.2560e+00,  4.2349e+00],\n",
       "         [-2.3203e+00,  2.4506e+00],\n",
       "         [ 2.3692e+00, -2.3611e+00],\n",
       "         [-7.2391e-01,  8.4393e-01],\n",
       "         [-3.4835e+00,  3.5685e+00],\n",
       "         [ 5.0128e+00, -4.9305e+00],\n",
       "         [-1.7530e+00,  1.7644e+00],\n",
       "         [-3.6014e+00,  3.6812e+00],\n",
       "         [ 1.7991e+00, -1.7602e+00],\n",
       "         [ 3.4194e+00, -3.3725e+00],\n",
       "         [ 1.8362e+00, -1.8362e+00],\n",
       "         [-1.5142e-01,  3.0233e-01],\n",
       "         [-1.4646e+00,  1.6578e+00],\n",
       "         [-3.1104e+00,  3.2037e+00],\n",
       "         [ 2.4501e-01, -1.8145e-01],\n",
       "         [ 2.7130e+00, -2.6288e+00],\n",
       "         [-4.0694e+00,  4.0856e+00],\n",
       "         [ 3.5367e+00, -3.4948e+00]]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(pd.read_csv(\"./data/test_2.csv\", delimiter=\",\"), vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For storing model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f1:\n",
    "    pickle.dump(model, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab.pkl', 'wb') as f1:\n",
    "    pickle.dump(vocab, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To send to Kristjan ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
